{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NCCL_P2P_DISABLE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask_xgboost as dxgb_gpu\n",
    "import dask\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, wait\n",
    "import xgboost as xgb\n",
    "import cudf\n",
    "from cudf.dataframe import DataFrame\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "from glob import glob\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = \"hostname --all-ip-addresses\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "IPADDR = str(output.decode()).split()[0]\n",
    "\n",
    "cluster = LocalCUDACluster(ip=IPADDR)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to download data for this notebook, visit https://docs.rapids.ai/datasets/mortgage-data and update the following paths accordingly\n",
    "acq_data_path = \"/data/kratos/mortgage_1yr/acq\"\n",
    "perf_data_path = \"/data/kratos/mortgage_1yr/perf\"\n",
    "col_names_path = \"/data/kratos/mortgage_1yr/names.csv\"\n",
    "start_year = 2000\n",
    "end_year = 2003 # end_year is inclusive\n",
    "part_count = 16 # the number of data files to train against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPLACE WITH NEW SETALLOCATOR\n",
    "def initialize_rmm_pool():\n",
    "    from librmm_cffi import librmm_config as rmm_cfg\n",
    "\n",
    "    rmm_cfg.use_pool_allocator = True\n",
    "    rmm_cfg.initial_pool_size = int(1.4e10) # set to 2GiB. Default is 1/2 total GPU memory\n",
    "    import cudf\n",
    "    return cudf.rmm.initialize()\n",
    "\n",
    "def initialize_rmm_no_pool():\n",
    "    from librmm_cffi import librmm_config as rmm_cfg\n",
    "    \n",
    "    rmm_cfg.use_pool_allocator = False\n",
    "    import cudf\n",
    "    return cudf.rmm.initialize()\n",
    "\n",
    "def finalize_rmm():\n",
    "    import cudf\n",
    "    return cudf.rmm.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(initialize_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO methods for loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_names_df(names_df_path, **kwargs):\n",
    "    \"\"\" Loads names used for renaming the banks\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dask GPU DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [\n",
    "        'seller_name', 'new'\n",
    "    ]\n",
    "    \n",
    "    dtypes = OrderedDict([\n",
    "        (\"seller_name\", \"category\"),\n",
    "        (\"new\", \"category\"),\n",
    "    ])\n",
    "\n",
    "    return dask_cudf.read_csv(names_df_path, names=cols, delimiter='|', dtype=list(dtypes.values()), skiprows=1)\n",
    "\n",
    "\n",
    "def load_perf_df(performance_path, **kwargs):\n",
    "    \"\"\" Loads performance data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GPU DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [\n",
    "        \"loan_id\", \"monthly_reporting_period\", \"servicer\", \"interest_rate\", \"current_actual_upb\",\n",
    "        \"loan_age\", \"remaining_months_to_legal_maturity\", \"adj_remaining_months_to_maturity\",\n",
    "        \"maturity_date\", \"msa\", \"current_loan_delinquency_status\", \"mod_flag\", \"zero_balance_code\",\n",
    "        \"zero_balance_effective_date\", \"last_paid_installment_date\", \"foreclosed_after\",\n",
    "        \"disposition_date\", \"foreclosure_costs\", \"prop_preservation_and_repair_costs\",\n",
    "        \"asset_recovery_costs\", \"misc_holding_expenses\", \"holding_taxes\", \"net_sale_proceeds\",\n",
    "        \"credit_enhancement_proceeds\", \"repurchase_make_whole_proceeds\", \"other_foreclosure_proceeds\",\n",
    "        \"non_interest_bearing_upb\", \"principal_forgiveness_upb\", \"repurchase_make_whole_proceeds_flag\",\n",
    "        \"foreclosure_principal_write_off_amount\", \"servicing_activity_indicator\"\n",
    "    ]\n",
    "    \n",
    "    dtypes = OrderedDict([\n",
    "        (\"loan_id\", \"int64\"),\n",
    "        (\"monthly_reporting_period\", \"date\"),\n",
    "        (\"servicer\", \"category\"),\n",
    "        (\"interest_rate\", \"float64\"),\n",
    "        (\"current_actual_upb\", \"float64\"),\n",
    "        (\"loan_age\", \"float64\"),\n",
    "        (\"remaining_months_to_legal_maturity\", \"float64\"),\n",
    "        (\"adj_remaining_months_to_maturity\", \"float64\"),\n",
    "        (\"maturity_date\", \"date\"),\n",
    "        (\"msa\", \"float64\"),\n",
    "        (\"current_loan_delinquency_status\", \"int32\"),\n",
    "        (\"mod_flag\", \"category\"),\n",
    "        (\"zero_balance_code\", \"category\"),\n",
    "        (\"zero_balance_effective_date\", \"date\"),\n",
    "        (\"last_paid_installment_date\", \"date\"),\n",
    "        (\"foreclosed_after\", \"date\"),\n",
    "        (\"disposition_date\", \"date\"),\n",
    "        (\"foreclosure_costs\", \"float64\"),\n",
    "        (\"prop_preservation_and_repair_costs\", \"float64\"),\n",
    "        (\"asset_recovery_costs\", \"float64\"),\n",
    "        (\"misc_holding_expenses\", \"float64\"),\n",
    "        (\"holding_taxes\", \"float64\"),\n",
    "        (\"net_sale_proceeds\", \"float64\"),\n",
    "        (\"credit_enhancement_proceeds\", \"float64\"),\n",
    "        (\"repurchase_make_whole_proceeds\", \"float64\"),\n",
    "        (\"other_foreclosure_proceeds\", \"float64\"),\n",
    "        (\"non_interest_bearing_upb\", \"float64\"),\n",
    "        (\"principal_forgiveness_upb\", \"float64\"),\n",
    "        (\"repurchase_make_whole_proceeds_flag\", \"category\"),\n",
    "        (\"foreclosure_principal_write_off_amount\", \"float64\"),\n",
    "        (\"servicing_activity_indicator\", \"category\")\n",
    "    ])\n",
    "\n",
    "    print(performance_path)\n",
    "    \n",
    "    return dask_cudf.read_csv(performance_path, names=cols, delimiter='|', dtype=list(dtypes.values()), skiprows=1)\n",
    "\n",
    "\n",
    "def load_acq_df(acquisition_path, **kwargs):\n",
    "    \"\"\" Loads acquisition data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GPU DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [\n",
    "        'loan_id', 'orig_channel', 'seller_name', 'orig_interest_rate', 'orig_upb', 'orig_loan_term', \n",
    "        'orig_date', 'first_pay_date', 'orig_ltv', 'orig_cltv', 'num_borrowers', 'dti', 'borrower_credit_score', \n",
    "        'first_home_buyer', 'loan_purpose', 'property_type', 'num_units', 'occupancy_status', 'property_state',\n",
    "        'zip', 'mortgage_insurance_percent', 'product_type', 'coborrow_credit_score', 'mortgage_insurance_type', \n",
    "        'relocation_mortgage_indicator'\n",
    "    ]\n",
    "    \n",
    "    dtypes = OrderedDict([\n",
    "        (\"loan_id\", \"int64\"),\n",
    "        (\"orig_channel\", \"category\"),\n",
    "        (\"seller_name\", \"category\"),\n",
    "        (\"orig_interest_rate\", \"float64\"),\n",
    "        (\"orig_upb\", \"int64\"),\n",
    "        (\"orig_loan_term\", \"int64\"),\n",
    "        (\"orig_date\", \"date\"),\n",
    "        (\"first_pay_date\", \"date\"),\n",
    "        (\"orig_ltv\", \"float64\"),\n",
    "        (\"orig_cltv\", \"float64\"),\n",
    "        (\"num_borrowers\", \"float64\"),\n",
    "        (\"dti\", \"float64\"),\n",
    "        (\"borrower_credit_score\", \"float64\"),\n",
    "        (\"first_home_buyer\", \"category\"),\n",
    "        (\"loan_purpose\", \"category\"),\n",
    "        (\"property_type\", \"category\"),\n",
    "        (\"num_units\", \"int64\"),\n",
    "        (\"occupancy_status\", \"category\"),\n",
    "        (\"property_state\", \"category\"),\n",
    "        (\"zip\", \"int64\"),\n",
    "        (\"mortgage_insurance_percent\", \"float64\"),\n",
    "        (\"product_type\", \"category\"),\n",
    "        (\"coborrow_credit_score\", \"float64\"),\n",
    "        (\"mortgage_insurance_type\", \"float64\"),\n",
    "        (\"relocation_mortgage_indicator\", \"category\")\n",
    "    ])\n",
    "    \n",
    "    print(acquisition_path)\n",
    "    return dask_cudf.read_csv(acquisition_path, names=cols, delimiter='|', dtype=list(dtypes.values()), skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ever_features(gdf, **kwargs):\n",
    "    everdf = gdf.groupby('loan_id').current_loan_delinquency_status.max().to_frame()\n",
    "    everdf['ever_30'] = (everdf['current_loan_delinquency_status'] >= 1).astype('int8')\n",
    "    everdf['ever_90'] = (everdf['current_loan_delinquency_status'] >= 3).astype('int8')\n",
    "    everdf['ever_180'] = (everdf['current_loan_delinquency_status'] >= 6).astype('int8')\n",
    "    everdf = everdf.map_partitions(cudf.DataFrame.drop,'current_loan_delinquency_status')\n",
    "    return everdf\n",
    "\n",
    "def create_delinq_features(gdf, **kwargs):\n",
    "    gdf['monthly_reporting_period'] = gdf['monthly_reporting_period'].astype(\"datetime64[ns]\")\n",
    "    delinq_30 = gdf.query('current_loan_delinquency_status >= 1').groupby('loan_id').monthly_reporting_period.min().to_frame()\n",
    "    delinq_30['delinquency_30'] = delinq_30['monthly_reporting_period']\n",
    "    delinq_30 = delinq_30.map_partitions(cudf.DataFrame.drop,'monthly_reporting_period')\n",
    "    \n",
    "    delinq_90 = gdf.query('current_loan_delinquency_status >= 3').groupby('loan_id').monthly_reporting_period.min().to_frame()\n",
    "    delinq_90['delinquency_90'] = delinq_90['monthly_reporting_period']\n",
    "    delinq_90 = delinq_90.map_partitions(cudf.DataFrame.drop,'monthly_reporting_period')\n",
    "    \n",
    "    delinq_180 = gdf.query('current_loan_delinquency_status >= 6').groupby('loan_id').monthly_reporting_period.min().to_frame()\n",
    "    delinq_180['delinquency_180'] = delinq_180['monthly_reporting_period']\n",
    "    delinq_180 = delinq_180.map_partitions(cudf.DataFrame.drop,'monthly_reporting_period')\n",
    "    delinq_merge = delinq_30.merge(delinq_90, how='left', left_index=True, right_index= True)\n",
    "    #delinq_merge['delinquency_90'] = delinq_merge['delinquency_90'].fillna(np.datetime64('1970-01-01').astype('datetime64[ms]'))\n",
    "    delinq_merge = delinq_merge.merge(delinq_180, how='left', left_index=True, right_index= True)\n",
    "    #delinq_merge['delinquency_180'] = delinq_merge['delinquency_180'].fillna(np.datetime64('1970-01-01').astype('datetime64[ms]'))\n",
    "    del(delinq_30)\n",
    "    del(delinq_90)\n",
    "    del(delinq_180)\n",
    "    return delinq_merge\n",
    "\n",
    "def create_12_mon_features(joined_df, **kwargs):\n",
    "    testdfs = []\n",
    "    n_months = 12\n",
    "    for y in range(1, n_months + 1):\n",
    "        tmpdf = joined_df[['loan_id', 'timestamp_year', 'timestamp_month', 'delinquency_12', 'upb_12']]\n",
    "        tmpdf['josh_months'] = tmpdf['timestamp_year'] * 12 + tmpdf['timestamp_month']\n",
    "        tmpdf['josh_mody_n'] = ((tmpdf['josh_months'].astype('float64') - 24000 - y) // 12)\n",
    "        tmpdf = tmpdf.groupby(['loan_id', 'josh_mody_n']).agg({'delinquency_12': 'max','upb_12': 'min'})\n",
    "        tmpdf = tmpdf.map_partitions(cudf.DataFrame.reset_index)\n",
    "        tmpdf['delinquency_12'] = (tmpdf['delinquency_12']>3).astype('int32')\n",
    "        tmpdf['delinquency_12'] +=(tmpdf['upb_12']==0).astype('int32')\n",
    "        tmpdf['timestamp_year'] = (((tmpdf['josh_mody_n'] * n_months) + 24000 + (y - 1)) // 12).astype('int16')\n",
    "        tmpdf['timestamp_month'] = np.int8(y)\n",
    "        tmpdf = tmpdf.map_partitions(cudf.DataFrame.drop,'josh_mody_n')\n",
    "        testdfs.append(tmpdf)\n",
    "        del(tmpdf)\n",
    "    \n",
    "    return dask.dataframe.concat(testdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joined_df(perf_df, ever_df, **kwargs):\n",
    "    temp = perf_df[['loan_id', 'monthly_reporting_period', 'current_loan_delinquency_status', 'current_actual_upb']]\n",
    "    temp['timestamp'] = temp['monthly_reporting_period']\n",
    "    temp = temp.map_partitions(cudf.DataFrame.drop,'monthly_reporting_period')\n",
    "    temp['timestamp_month'] = temp['timestamp'].dt.month\n",
    "    temp['timestamp_year'] = temp['timestamp'].dt.year\n",
    "    temp['delinquency_12'] = temp['current_loan_delinquency_status']\n",
    "    temp = temp.map_partitions(cudf.DataFrame.drop,'current_loan_delinquency_status')\n",
    "    temp['upb_12'] = temp['current_actual_upb']\n",
    "    temp.map_partitions(cudf.DataFrame.drop,'current_actual_upb')\n",
    "    #test['upb_12'] = test['upb_12'].fillna(999999999)\n",
    "    #test['delinquency_12'] = test['delinquency_12'].fillna(-1)\n",
    "    ever_df = ever_df.map_partitions(cudf.DataFrame.reset_index)\n",
    "    joined_df = temp.merge(ever_df, how='left', on='loan_id')\n",
    "    \n",
    "    #joined_df['ever_30'] = joined_df['ever_30'].fillna(-1)\n",
    "    #joined_df['ever_90'] = joined_df['ever_90'].fillna(-1)\n",
    "    #joined_df['ever_180'] = joined_df['ever_180'].fillna(-1)\n",
    "    #joined_df['delinquency_30'] = joined_df['delinquency_30'].fillna(-1)\n",
    "    #joined_df['delinquency_90'] = joined_df['delinquency_90'].fillna(-1)\n",
    "    #joined_df['delinquency_180'] = joined_df['delinquency_180'].fillna(-1)\n",
    "    \n",
    "    joined_df['timestamp_year'] = joined_df['timestamp_year'].astype('int32')\n",
    "    joined_df['timestamp_month'] = joined_df['timestamp_month'].astype('int32')\n",
    "    \n",
    "    return joined_df\n",
    "\n",
    "def combine_joined_12_mon(joined_df, testdf, **kwargs):\n",
    "    joined_df = joined_df.map_partitions(cudf.DataFrame.drop, ['delinquency_12','upb_12'])\n",
    "    joined_df['timestamp_year'] = joined_df['timestamp_year'].astype('int16')\n",
    "    joined_df['timestamp_month'] = joined_df['timestamp_month'].astype('int8')\n",
    "    joined_df = joined_df.merge(testdf, how='left', on=['loan_id', 'timestamp_year', 'timestamp_month'])\n",
    "    return joined_df\n",
    "\n",
    "def final_performance_delinquency(joined_df, perf_df):\n",
    "    perf_df['timestamp_month'] = perf_df['monthly_reporting_period'].dt.month\n",
    "    perf_df['timestamp_month'] = perf_df['timestamp_month'].astype('int8')\n",
    "    perf_df['timestamp_year'] = perf_df['monthly_reporting_period'].dt.year\n",
    "    perf_df['timestamp_year'] = perf_df['timestamp_year'].astype('int16')\n",
    "    #Workaround for issue rapidsai/cudf#2705\n",
    "    perf_df['maturity_date'] = perf_df['maturity_date'].astype(\"datetime64[ns]\")\n",
    "    perf_df['zero_balance_effective_date'] = perf_df['zero_balance_effective_date'].astype(\"datetime64[ns]\")\n",
    "    perf_df['last_paid_installment_date'] = perf_df['last_paid_installment_date'].astype(\"datetime64[ns]\")\n",
    "    perf_df['foreclosed_after'] = perf_df['foreclosed_after'].astype(\"datetime64[ns]\")\n",
    "    perf_df['disposition_date'] = perf_df['disposition_date'].astype(\"datetime64[ns]\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    perf_df = perf_df.merge(joined_df, how='left', on=['loan_id', 'timestamp_year', 'timestamp_month'])\n",
    "    perf_df.map_partitions(cudf.DataFrame.drop,'timestamp_year')\n",
    "    perf_df.map_partitions(cudf.DataFrame.drop,'timestamp_month')\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = load_names_df(\"file://\"+col_names_path)\n",
    "perf_df = load_perf_df(\"file://\"+perf_data_path+\"/*\")\n",
    "perf_df = perf_df.repartition(npartitions=5)\n",
    "acq_df = load_acq_df(\"file://\"+acq_data_path+\"/*\")\n",
    "acq = perf_df.repartition(npartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_df = acq_df.merge(names_df, how='left', on='seller_name')\n",
    "acq_df = acq_df.map_partitions(cudf.DataFrame.drop,'seller_name')\n",
    "acq_df = acq_df.rename(columns={'new':'seller_name'})\n",
    "ever_df = create_ever_features(perf_df)\n",
    "delinq_merged_df = create_delinq_features(perf_df)\n",
    "ever_df = ever_df.merge(delinq_merged_df, how='left', left_index=True, right_index= True)\n",
    "del(delinq_merged_df)\n",
    "joined_df = create_joined_df(perf_df, ever_df)\n",
    "joined_df_2 = create_12_mon_features(joined_df)\n",
    "joined_df = combine_joined_12_mon(joined_df, joined_df_2)\n",
    "del(joined_df_2)\n",
    "perf_df_final = final_performance_delinquency(joined_df, perf_df)\n",
    "del(joined_df)\n",
    "acq_df['orig_date'] = acq_df['orig_date'].astype(\"datetime64[ns]\")\n",
    "acq_df['first_pay_date'] = acq_df['first_pay_date'].astype(\"datetime64[ns]\")\n",
    "\n",
    "df_final = perf_df_final.merge(acq_df, how='left', on=['loan_id'])\n",
    "\n",
    "\n",
    "drop_list = [\n",
    "        'loan_id', 'orig_date', 'first_pay_date', 'seller_name',\n",
    "        'monthly_reporting_period', 'last_paid_installment_date', 'maturity_date', 'ever_30', 'ever_90', 'ever_180',\n",
    "        'delinquency_30', 'delinquency_90', 'delinquency_180', 'upb_12',\n",
    "        'zero_balance_effective_date','foreclosed_after', 'disposition_date','timestamp'\n",
    "    ]\n",
    "df_final = df_final.map_partitions(cudf.DataFrame.drop, drop_list)\n",
    "df_arrow = df_final.map_partitions(cudf.DataFrame.to_arrow,preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time len(df_arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(finalize_rmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(initialize_rmm_no_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxgb_gpu_params = {\n",
    "    'nround':            100,\n",
    "    'max_depth':         8,\n",
    "    'max_leaves':        2**8,\n",
    "    'alpha':             0.9,\n",
    "    'eta':               0.1,\n",
    "    'gamma':             0.1,\n",
    "    'learning_rate':     0.1,\n",
    "    'subsample':         1,\n",
    "    'reg_lambda':        1,\n",
    "    'scale_pos_weight':  2,\n",
    "    'min_child_weight':  30,\n",
    "    'tree_method':       'gpu_hist',\n",
    "    'n_gpus':            1,\n",
    "    'distributed_dask':  True,\n",
    "    'loss':              'ls',\n",
    "    'objective':         'gpu:reg:linear',\n",
    "    'max_features':      'auto',\n",
    "    'criterion':         'friedman_mse',\n",
    "    'grow_policy':       'lossguide',\n",
    "    'verbose':           True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dfs = [delayed(cudf.DataFrame.from_arrow)(gpu_df) for gpu_df in df_arrow]\n",
    "wait(gpu_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
